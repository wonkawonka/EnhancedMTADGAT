{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c26aa4b8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-08T12:37:49.135632Z",
     "iopub.status.busy": "2025-05-08T12:37:49.135406Z",
     "iopub.status.idle": "2025-05-08T12:37:50.519706Z",
     "shell.execute_reply": "2025-05-08T12:37:50.519133Z"
    },
    "papermill": {
     "duration": 1.388852,
     "end_time": "2025-05-08T12:37:50.521078",
     "exception": false,
     "start_time": "2025-05-08T12:37:49.132226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b1be718",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:37:50.527596Z",
     "iopub.status.busy": "2025-05-08T12:37:50.526995Z",
     "iopub.status.idle": "2025-05-08T12:37:50.682930Z",
     "shell.execute_reply": "2025-05-08T12:37:50.682176Z"
    },
    "papermill": {
     "duration": 0.16094,
     "end_time": "2025-05-08T12:37:50.684385",
     "exception": false,
     "start_time": "2025-05-08T12:37:50.523445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\r\n",
      "\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\r\n",
      "\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\r\n",
      "\u001b[33mhint: \u001b[m\r\n",
      "\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\r\n",
      "\u001b[33mhint: \u001b[m\r\n",
      "\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\r\n",
      "\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\r\n",
      "\u001b[33mhint: \u001b[m\r\n",
      "\u001b[33mhint: \tgit branch -m <name>\u001b[m\r\n",
      "Initialized empty Git repository in /kaggle/working/.git/\r\n"
     ]
    }
   ],
   "source": [
    "!git init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "065780ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:37:50.690060Z",
     "iopub.status.busy": "2025-05-08T12:37:50.689515Z",
     "iopub.status.idle": "2025-05-08T12:38:27.172561Z",
     "shell.execute_reply": "2025-05-08T12:38:27.171633Z"
    },
    "papermill": {
     "duration": 36.48738,
     "end_time": "2025-05-08T12:38:27.174010",
     "exception": false,
     "start_time": "2025-05-08T12:37:50.686630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'EnhancedMTADGAT'...\r\n",
      "remote: Enumerating objects: 6255, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (52/52), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (41/41), done.\u001b[K\r\n",
      "remote: Total 6255 (delta 25), reused 32 (delta 10), pack-reused 6203 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (6255/6255), 933.83 MiB | 39.67 MiB/s, done.\r\n",
      "Resolving deltas: 100% (2762/2762), done.\r\n",
      "Updating files: 100% (165/165), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/wonkawonka/EnhancedMTADGAT.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65d0fdf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:38:27.189037Z",
     "iopub.status.busy": "2025-05-08T12:38:27.188454Z",
     "iopub.status.idle": "2025-05-08T12:38:27.194941Z",
     "shell.execute_reply": "2025-05-08T12:38:27.194295Z"
    },
    "papermill": {
     "duration": 0.01466,
     "end_time": "2025-05-08T12:38:27.196010",
     "exception": false,
     "start_time": "2025-05-08T12:38:27.181350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/EnhancedMTADGAT\n"
     ]
    }
   ],
   "source": [
    "cd EnhancedMTADGAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37b47f11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:38:27.208377Z",
     "iopub.status.busy": "2025-05-08T12:38:27.208147Z",
     "iopub.status.idle": "2025-05-08T12:55:22.021444Z",
     "shell.execute_reply": "2025-05-08T12:55:22.020706Z"
    },
    "papermill": {
     "duration": 1014.821107,
     "end_time": "2025-05-08T12:55:22.022880",
     "exception": false,
     "start_time": "2025-05-08T12:38:27.201773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-08 12:38:35.171941: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1746707915.370940      55 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1746707915.425997      55 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "{'dynamic_graph': False, 'correlation_aware': False, 'use_transformer': False, 'dataset': 'SMAP', 'group': '1-1', 'lookback': 100, 'normalize': True, 'spec_res': False, 'kernel_size': 7, 'use_gatv2': True, 'feat_gat_embed_dim': None, 'time_gat_embed_dim': None, 'trans_enc_layers': 2, 'gru_n_layers': 2, 'gru_hid_dim': 150, 'fc_n_layers': 3, 'fc_hid_dim': 150, 'recon_n_layers': 1, 'recon_hid_dim': 150, 'alpha': 0.2, 'epochs': 10, 'val_split': 0.1, 'bs': 256, 'init_lr': 0.0001, 'shuffle_dataset': True, 'dropout': 0.3, 'use_cuda': True, 'print_every': 1, 'log_tensorboard': True, 'scale_scores': False, 'use_mov_av': False, 'gamma': 1, 'level': None, 'q': None, 'dynamic_pot': False, 'comment': ''}\r\n",
      "load data of: SMAP\r\n",
      "train:  0 None\r\n",
      "test:  0 None\r\n",
      "Data normalized\r\n",
      "Data normalized\r\n",
      "train set shape:  (135183, 25)\r\n",
      "test set shape:  (427617, 25)\r\n",
      "test set label shape:  (427617,)\r\n",
      "Will forecast and reconstruct input features: [0]\r\n",
      "train_size: 121575\r\n",
      "validation_size: 13508\r\n",
      "test_size: 427517\r\n",
      "Init total train loss: 1.011715\r\n",
      "Init total val loss: 1.00591\r\n",
      "Training model for 10 epochs..\r\n",
      "[Epoch 1] forecast_loss = 0.24164, recon_loss = 0.27106, total_loss = 0.51270 ---- val_forecast_loss = 0.10792, val_recon_loss = 0.19503, val_total_loss = 0.30295 [59.2s]\r\n",
      "[Epoch 2] forecast_loss = 0.11411, recon_loss = 0.18510, total_loss = 0.29921 ---- val_forecast_loss = 0.08869, val_recon_loss = 0.17226, val_total_loss = 0.26095 [58.9s]\r\n",
      "[Epoch 3] forecast_loss = 0.10291, recon_loss = 0.16836, total_loss = 0.27127 ---- val_forecast_loss = 0.08737, val_recon_loss = 0.15968, val_total_loss = 0.24705 [59.0s]\r\n",
      "[Epoch 4] forecast_loss = 0.09732, recon_loss = 0.15385, total_loss = 0.25117 ---- val_forecast_loss = 0.08480, val_recon_loss = 0.14255, val_total_loss = 0.22735 [58.6s]\r\n",
      "[Epoch 5] forecast_loss = 0.09306, recon_loss = 0.13438, total_loss = 0.22744 ---- val_forecast_loss = 0.08636, val_recon_loss = 0.11696, val_total_loss = 0.20332 [58.8s]\r\n",
      "[Epoch 6] forecast_loss = 0.08991, recon_loss = 0.11095, total_loss = 0.20086 ---- val_forecast_loss = 0.07865, val_recon_loss = 0.10600, val_total_loss = 0.18465 [58.8s]\r\n",
      "[Epoch 7] forecast_loss = 0.08718, recon_loss = 0.09943, total_loss = 0.18661 ---- val_forecast_loss = 0.07376, val_recon_loss = 0.09163, val_total_loss = 0.16539 [58.7s]\r\n",
      "[Epoch 8] forecast_loss = 0.08473, recon_loss = 0.09250, total_loss = 0.17723 ---- val_forecast_loss = 0.07704, val_recon_loss = 0.08797, val_total_loss = 0.16501 [58.7s]\r\n",
      "[Epoch 9] forecast_loss = 0.08322, recon_loss = 0.08725, total_loss = 0.17047 ---- val_forecast_loss = 0.07445, val_recon_loss = 0.08361, val_total_loss = 0.15806 [58.7s]\r\n",
      "[Epoch 10] forecast_loss = 0.08160, recon_loss = 0.08329, total_loss = 0.16489 ---- val_forecast_loss = 0.07323, val_recon_loss = 0.07937, val_total_loss = 0.15260 [58.5s]\r\n",
      "-- Training done in 587s.\r\n",
      "Test forecast loss: 0.07193\r\n",
      "Test reconstruction loss: 0.07168\r\n",
      "Test total loss: 0.14361\r\n",
      "/kaggle/working/EnhancedMTADGAT/training.py:248: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  self.model.load_state_dict(torch.load(PATH, map_location=self.device))\r\n",
      "Predicting and calculating anomaly scores..\r\n",
      "100%|█████████████████████████████████████████| 528/528 [00:56<00:00,  9.42it/s]\r\n",
      "Predicting and calculating anomaly scores..\r\n",
      "100%|███████████████████████████████████████| 1670/1670 [02:57<00:00,  9.39it/s]\r\n",
      "Running POT with q=0.005, level=0.9..\r\n",
      "Initial threshold : 0.39634168\r\n",
      "Number of peaks : 13508\r\n",
      "Grimshaw maximum log-likelihood estimation ... [done]\r\n",
      "\tγ = -0.021643776446580887\r\n",
      "\tσ = 0.1622323985103577\r\n",
      "\tL = 11351.70685329734\r\n",
      "Extreme quantile (probability = 0.005): 0.8669221984523432\r\n",
      "100%|██████████████████████████████| 427517/427517 [00:00<00:00, 2297234.51it/s]\r\n",
      "0\r\n",
      "427517\r\n",
      "Finding best f1-score by searching for threshold..\r\n",
      "Results using epsilon method:\r\n",
      " {'f1': 0.8464520464712544, 'precision': 0.9615375669228803, 'recall': 0.7559784992036019, 'TP': 41349, 'TN': 371167, 'FP': 1654, 'FN': 13347, 'threshold': 0.6036378145217896, 'latency': 131.08748932019418, 'reg_level': 0}\r\n",
      "Results using peak-over-threshold method:\r\n",
      " {'f1': 0.7796269119829471, 'precision': 0.9913666626251645, 'recall': 0.6424235774750578, 'TP': 35138, 'TN': 372515, 'FP': 306, 'FN': 19558, 'threshold': 0.8669221984523433, 'latency': 159.6731435241969}\r\n",
      "Results using best f1 score search:\r\n",
      " {'f1': 0.9305888321617867, 'precision': 0.8920863307856507, 'recall': 0.9725756909147696, 'TP': 53196, 'TN': 366386, 'FP': 6435, 'FN': 1500, 'threshold': 0.3881000000000002, 'latency': 210.62089299864695}\r\n",
      "Saving output to output/SMAP/08052025_123845/<train/test>_output.pkl\r\n",
      "-- Done.\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataset SMAP --lookback 100 --epochs 10 --init_lr 1e-4 --use_transformer False --gru_n_layers 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17d8db46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:55:22.210372Z",
     "iopub.status.busy": "2025-05-08T12:55:22.209664Z",
     "iopub.status.idle": "2025-05-08T13:13:41.289388Z",
     "shell.execute_reply": "2025-05-08T13:13:41.288446Z"
    },
    "papermill": {
     "duration": 1099.17213,
     "end_time": "2025-05-08T13:13:41.290864",
     "exception": false,
     "start_time": "2025-05-08T12:55:22.118734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-08 12:55:25.716984: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1746708925.739418      73 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1746708925.746152      73 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "{'dynamic_graph': False, 'correlation_aware': False, 'use_transformer': True, 'dataset': 'SMAP', 'group': '1-1', 'lookback': 100, 'normalize': True, 'spec_res': False, 'kernel_size': 7, 'use_gatv2': True, 'feat_gat_embed_dim': None, 'time_gat_embed_dim': None, 'trans_enc_layers': 2, 'gru_n_layers': 1, 'gru_hid_dim': 150, 'fc_n_layers': 3, 'fc_hid_dim': 150, 'recon_n_layers': 1, 'recon_hid_dim': 150, 'alpha': 0.2, 'epochs': 10, 'val_split': 0.1, 'bs': 256, 'init_lr': 0.0001, 'shuffle_dataset': True, 'dropout': 0.3, 'use_cuda': True, 'print_every': 1, 'log_tensorboard': True, 'scale_scores': False, 'use_mov_av': False, 'gamma': 1, 'level': None, 'q': None, 'dynamic_pot': False, 'comment': ''}\r\n",
      "load data of: SMAP\r\n",
      "train:  0 None\r\n",
      "test:  0 None\r\n",
      "Data normalized\r\n",
      "Data normalized\r\n",
      "train set shape:  (135183, 25)\r\n",
      "test set shape:  (427617, 25)\r\n",
      "test set label shape:  (427617,)\r\n",
      "Will forecast and reconstruct input features: [0]\r\n",
      "train_size: 121575\r\n",
      "validation_size: 13508\r\n",
      "test_size: 427517\r\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\r\n",
      "  warnings.warn(\r\n",
      "Init total train loss: 1.235678\r\n",
      "Init total val loss: 1.23630\r\n",
      "Training model for 10 epochs..\r\n",
      "[Epoch 1] forecast_loss = 0.27749, recon_loss = 0.27054, total_loss = 0.54803 ---- val_forecast_loss = 0.14029, val_recon_loss = 0.20553, val_total_loss = 0.34582 [69.8s]\r\n",
      "[Epoch 2] forecast_loss = 0.14020, recon_loss = 0.18111, total_loss = 0.32131 ---- val_forecast_loss = 0.09845, val_recon_loss = 0.16748, val_total_loss = 0.26593 [69.6s]\r\n",
      "[Epoch 3] forecast_loss = 0.11818, recon_loss = 0.14654, total_loss = 0.26473 ---- val_forecast_loss = 0.10455, val_recon_loss = 0.12916, val_total_loss = 0.23370 [69.4s]\r\n",
      "[Epoch 4] forecast_loss = 0.10948, recon_loss = 0.11883, total_loss = 0.22831 ---- val_forecast_loss = 0.08893, val_recon_loss = 0.10578, val_total_loss = 0.19472 [69.6s]\r\n",
      "[Epoch 5] forecast_loss = 0.10341, recon_loss = 0.10041, total_loss = 0.20381 ---- val_forecast_loss = 0.08380, val_recon_loss = 0.09492, val_total_loss = 0.17872 [69.6s]\r\n",
      "[Epoch 6] forecast_loss = 0.09973, recon_loss = 0.09318, total_loss = 0.19292 ---- val_forecast_loss = 0.08270, val_recon_loss = 0.08701, val_total_loss = 0.16971 [69.8s]\r\n",
      "[Epoch 7] forecast_loss = 0.09699, recon_loss = 0.08761, total_loss = 0.18460 ---- val_forecast_loss = 0.08028, val_recon_loss = 0.08236, val_total_loss = 0.16264 [70.0s]\r\n",
      "[Epoch 8] forecast_loss = 0.09333, recon_loss = 0.08213, total_loss = 0.17546 ---- val_forecast_loss = 0.08034, val_recon_loss = 0.07679, val_total_loss = 0.15713 [70.2s]\r\n",
      "[Epoch 9] forecast_loss = 0.09100, recon_loss = 0.07770, total_loss = 0.16870 ---- val_forecast_loss = 0.08330, val_recon_loss = 0.07586, val_total_loss = 0.15916 [69.5s]\r\n",
      "[Epoch 10] forecast_loss = 0.08911, recon_loss = 0.07485, total_loss = 0.16396 ---- val_forecast_loss = 0.06704, val_recon_loss = 0.07375, val_total_loss = 0.14079 [70.1s]\r\n",
      "-- Training done in 697s.\r\n",
      "Test forecast loss: 0.06752\r\n",
      "Test reconstruction loss: 0.06812\r\n",
      "Test total loss: 0.13565\r\n",
      "/kaggle/working/EnhancedMTADGAT/training.py:248: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  self.model.load_state_dict(torch.load(PATH, map_location=self.device))\r\n",
      "Predicting and calculating anomaly scores..\r\n",
      "100%|█████████████████████████████████████████| 528/528 [00:54<00:00,  9.70it/s]\r\n",
      "Predicting and calculating anomaly scores..\r\n",
      "100%|███████████████████████████████████████| 1670/1670 [02:53<00:00,  9.64it/s]\r\n",
      "Running POT with q=0.005, level=0.9..\r\n",
      "Initial threshold : 0.4642211\r\n",
      "Number of peaks : 12918\r\n",
      "Grimshaw maximum log-likelihood estimation ... [done]\r\n",
      "\tγ = -0.05117267370223999\r\n",
      "\tσ = 0.24723142348234406\r\n",
      "\tL = 5795.055348578451\r\n",
      "Extreme quantile (probability = 0.005): 1.1413957504503776\r\n",
      "100%|██████████████████████████████| 427517/427517 [00:00<00:00, 2250023.86it/s]\r\n",
      "0\r\n",
      "427517\r\n",
      "Finding best f1-score by searching for threshold..\r\n",
      "Results using epsilon method:\r\n",
      " {'f1': 0.8697752728977443, 'precision': 0.975608647001521, 'recall': 0.784664326315514, 'TP': 42918, 'TN': 371748, 'FP': 1073, 'FN': 11778, 'threshold': 0.6887684166431427, 'latency': 229.6202937581142, 'reg_level': 0}\r\n",
      "Results using peak-over-threshold method:\r\n",
      " {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'TP': 0, 'TN': 372821, 'FP': 0, 'FN': 54696, 'threshold': 1.1413957504503778, 'latency': 0.0}\r\n",
      "Results using best f1 score search:\r\n",
      " {'f1': 0.9027108194738221, 'precision': 0.8226818078028605, 'recall': 0.9999999998171712, 'TP': 54696, 'TN': 361032, 'FP': 11789, 'FN': 0, 'threshold': 0.32840000000000014, 'latency': 100.95507320138327}\r\n",
      "Saving output to output/SMAP/08052025_125528/<train/test>_output.pkl\r\n",
      "-- Done.\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataset SMAP --lookback 100 --epochs 10 --init_lr 1e-4 --use_transformer True --trans_enc_layers 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff30463a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T13:13:41.641392Z",
     "iopub.status.busy": "2025-05-08T13:13:41.640850Z",
     "iopub.status.idle": "2025-05-08T13:34:31.380565Z",
     "shell.execute_reply": "2025-05-08T13:34:31.379830Z"
    },
    "papermill": {
     "duration": 1249.913851,
     "end_time": "2025-05-08T13:34:31.381947",
     "exception": false,
     "start_time": "2025-05-08T13:13:41.468096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-08 13:13:45.131609: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1746710025.153978      91 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1746710025.160725      91 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "{'dynamic_graph': False, 'correlation_aware': False, 'use_transformer': False, 'dataset': 'SMAP', 'group': '1-1', 'lookback': 100, 'normalize': True, 'spec_res': False, 'kernel_size': 7, 'use_gatv2': True, 'feat_gat_embed_dim': None, 'time_gat_embed_dim': None, 'trans_enc_layers': 2, 'gru_n_layers': 4, 'gru_hid_dim': 150, 'fc_n_layers': 3, 'fc_hid_dim': 150, 'recon_n_layers': 1, 'recon_hid_dim': 150, 'alpha': 0.2, 'epochs': 10, 'val_split': 0.1, 'bs': 256, 'init_lr': 0.001, 'shuffle_dataset': True, 'dropout': 0.3, 'use_cuda': True, 'print_every': 1, 'log_tensorboard': True, 'scale_scores': False, 'use_mov_av': False, 'gamma': 1, 'level': None, 'q': None, 'dynamic_pot': False, 'comment': ''}\r\n",
      "load data of: SMAP\r\n",
      "train:  0 None\r\n",
      "test:  0 None\r\n",
      "Data normalized\r\n",
      "Data normalized\r\n",
      "train set shape:  (135183, 25)\r\n",
      "test set shape:  (427617, 25)\r\n",
      "test set label shape:  (427617,)\r\n",
      "Will forecast and reconstruct input features: [0]\r\n",
      "train_size: 121575\r\n",
      "validation_size: 13508\r\n",
      "test_size: 427517\r\n",
      "Init total train loss: 1.130071\r\n",
      "Init total val loss: 1.13347\r\n",
      "Training model for 10 epochs..\r\n",
      "[Epoch 1] forecast_loss = 0.14882, recon_loss = 0.18718, total_loss = 0.33600 ---- val_forecast_loss = 0.08692, val_recon_loss = 0.10857, val_total_loss = 0.19549 [73.2s]\r\n",
      "[Epoch 2] forecast_loss = 0.08877, recon_loss = 0.08713, total_loss = 0.17590 ---- val_forecast_loss = 0.07226, val_recon_loss = 0.07424, val_total_loss = 0.14650 [73.1s]\r\n",
      "[Epoch 3] forecast_loss = 0.08264, recon_loss = 0.07506, total_loss = 0.15770 ---- val_forecast_loss = 0.07026, val_recon_loss = 0.07072, val_total_loss = 0.14098 [72.9s]\r\n",
      "[Epoch 4] forecast_loss = 0.07897, recon_loss = 0.06995, total_loss = 0.14892 ---- val_forecast_loss = 0.06638, val_recon_loss = 0.07017, val_total_loss = 0.13654 [73.1s]\r\n",
      "[Epoch 5] forecast_loss = 0.07718, recon_loss = 0.06759, total_loss = 0.14477 ---- val_forecast_loss = 0.07017, val_recon_loss = 0.06312, val_total_loss = 0.13330 [73.2s]\r\n",
      "[Epoch 6] forecast_loss = 0.07561, recon_loss = 0.06446, total_loss = 0.14007 ---- val_forecast_loss = 0.06498, val_recon_loss = 0.05997, val_total_loss = 0.12495 [73.4s]\r\n",
      "[Epoch 7] forecast_loss = 0.07472, recon_loss = 0.06277, total_loss = 0.13749 ---- val_forecast_loss = 0.06203, val_recon_loss = 0.05665, val_total_loss = 0.11868 [73.3s]\r\n",
      "[Epoch 8] forecast_loss = 0.07357, recon_loss = 0.06094, total_loss = 0.13450 ---- val_forecast_loss = 0.06554, val_recon_loss = 0.05783, val_total_loss = 0.12337 [73.4s]\r\n",
      "[Epoch 9] forecast_loss = 0.07166, recon_loss = 0.05841, total_loss = 0.13007 ---- val_forecast_loss = 0.06145, val_recon_loss = 0.05392, val_total_loss = 0.11537 [73.1s]\r\n",
      "[Epoch 10] forecast_loss = 0.07272, recon_loss = 0.05853, total_loss = 0.13125 ---- val_forecast_loss = 0.06234, val_recon_loss = 0.05436, val_total_loss = 0.11670 [73.4s]\r\n",
      "-- Training done in 732s.\r\n",
      "Test forecast loss: 0.06428\r\n",
      "Test reconstruction loss: 0.05568\r\n",
      "Test total loss: 0.11997\r\n",
      "/kaggle/working/EnhancedMTADGAT/training.py:248: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  self.model.load_state_dict(torch.load(PATH, map_location=self.device))\r\n",
      "Predicting and calculating anomaly scores..\r\n",
      "100%|█████████████████████████████████████████| 528/528 [01:13<00:00,  7.22it/s]\r\n",
      "Predicting and calculating anomaly scores..\r\n",
      "100%|███████████████████████████████████████| 1670/1670 [03:51<00:00,  7.20it/s]\r\n",
      "Running POT with q=0.005, level=0.9..\r\n",
      "Initial threshold : 0.43519238\r\n",
      "Number of peaks : 13508\r\n",
      "Grimshaw maximum log-likelihood estimation ... [done]\r\n",
      "\tγ = -0.12301300466060638\r\n",
      "\tσ = 0.1995790953969236\r\n",
      "\tL = 9922.404833400402\r\n",
      "Extreme quantile (probability = 0.005): 0.9352824514575974\r\n",
      "100%|██████████████████████████████| 427517/427517 [00:00<00:00, 2268216.47it/s]\r\n",
      "0\r\n",
      "427517\r\n",
      "Finding best f1-score by searching for threshold..\r\n",
      "Results using epsilon method:\r\n",
      " {'f1': 0.8463973303273846, 'precision': 0.9835625058139917, 'recall': 0.7428148309304492, 'TP': 40629, 'TN': 372142, 'FP': 679, 'FN': 14067, 'threshold': 0.6792006269097328, 'latency': 169.23700129321813, 'reg_level': 0}\r\n",
      "Results using peak-over-threshold method:\r\n",
      " {'f1': 0.7889759179295063, 'precision': 0.9947697868981026, 'recall': 0.6537406756154489, 'TP': 35757, 'TN': 372633, 'FP': 188, 'FN': 18939, 'threshold': 0.9352824514575975, 'latency': 227.39954520090959}\r\n",
      "Results using best f1 score search:\r\n",
      " {'f1': 0.9445093512860285, 'precision': 0.9490208381570311, 'recall': 0.9400504605565213, 'TP': 51417, 'TN': 370059, 'FP': 2762, 'FN': 3279, 'threshold': 0.46770000000000034, 'latency': 172.78434956253912}\r\n",
      "Saving output to output/SMAP/08052025_131347/<train/test>_output.pkl\r\n",
      "-- Done.\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataset SMAP --lookback 100 --epochs 10 --init_lr 1e-3 --use_transformer False --gru_n_layers 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52461974",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T13:34:31.914724Z",
     "iopub.status.busy": "2025-05-08T13:34:31.914450Z",
     "iopub.status.idle": "2025-05-08T13:52:55.194390Z",
     "shell.execute_reply": "2025-05-08T13:52:55.193653Z"
    },
    "papermill": {
     "duration": 1103.543176,
     "end_time": "2025-05-08T13:52:55.195639",
     "exception": false,
     "start_time": "2025-05-08T13:34:31.652463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-08 13:34:35.473949: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1746711275.497469     109 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1746711275.504553     109 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "{'dynamic_graph': False, 'correlation_aware': False, 'use_transformer': True, 'dataset': 'SMAP', 'group': '1-1', 'lookback': 100, 'normalize': True, 'spec_res': False, 'kernel_size': 7, 'use_gatv2': True, 'feat_gat_embed_dim': None, 'time_gat_embed_dim': None, 'trans_enc_layers': 4, 'gru_n_layers': 1, 'gru_hid_dim': 150, 'fc_n_layers': 3, 'fc_hid_dim': 150, 'recon_n_layers': 1, 'recon_hid_dim': 150, 'alpha': 0.2, 'epochs': 10, 'val_split': 0.1, 'bs': 256, 'init_lr': 0.001, 'shuffle_dataset': True, 'dropout': 0.3, 'use_cuda': True, 'print_every': 1, 'log_tensorboard': True, 'scale_scores': False, 'use_mov_av': False, 'gamma': 1, 'level': None, 'q': None, 'dynamic_pot': False, 'comment': ''}\r\n",
      "load data of: SMAP\r\n",
      "train:  0 None\r\n",
      "test:  0 None\r\n",
      "Data normalized\r\n",
      "Data normalized\r\n",
      "train set shape:  (135183, 25)\r\n",
      "test set shape:  (427617, 25)\r\n",
      "test set label shape:  (427617,)\r\n",
      "Will forecast and reconstruct input features: [0]\r\n",
      "train_size: 121575\r\n",
      "validation_size: 13508\r\n",
      "test_size: 427517\r\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\r\n",
      "  warnings.warn(\r\n",
      "Init total train loss: 1.170996\r\n",
      "Init total val loss: 1.17268\r\n",
      "Training model for 10 epochs..\r\n",
      "[Epoch 1] forecast_loss = 0.18748, recon_loss = 0.20478, total_loss = 0.39226 ---- val_forecast_loss = 0.09534, val_recon_loss = 0.08871, val_total_loss = 0.18405 [70.2s]\r\n",
      "[Epoch 2] forecast_loss = 0.08899, recon_loss = 0.08000, total_loss = 0.16898 ---- val_forecast_loss = 0.08593, val_recon_loss = 0.07306, val_total_loss = 0.15899 [70.1s]\r\n",
      "[Epoch 3] forecast_loss = 0.08288, recon_loss = 0.06982, total_loss = 0.15270 ---- val_forecast_loss = 0.07059, val_recon_loss = 0.06596, val_total_loss = 0.13655 [69.9s]\r\n",
      "[Epoch 4] forecast_loss = 0.07833, recon_loss = 0.06457, total_loss = 0.14290 ---- val_forecast_loss = 0.06484, val_recon_loss = 0.05983, val_total_loss = 0.12467 [70.2s]\r\n",
      "[Epoch 5] forecast_loss = 0.07681, recon_loss = 0.06036, total_loss = 0.13717 ---- val_forecast_loss = 0.06982, val_recon_loss = 0.05450, val_total_loss = 0.12432 [70.2s]\r\n",
      "[Epoch 6] forecast_loss = 0.07477, recon_loss = 0.05662, total_loss = 0.13139 ---- val_forecast_loss = 0.06658, val_recon_loss = 0.05572, val_total_loss = 0.12230 [70.2s]\r\n",
      "[Epoch 7] forecast_loss = 0.07426, recon_loss = 0.05523, total_loss = 0.12950 ---- val_forecast_loss = 0.06122, val_recon_loss = 0.05219, val_total_loss = 0.11340 [70.2s]\r\n",
      "[Epoch 8] forecast_loss = 0.07276, recon_loss = 0.05379, total_loss = 0.12655 ---- val_forecast_loss = 0.06668, val_recon_loss = 0.05337, val_total_loss = 0.12005 [70.2s]\r\n",
      "[Epoch 9] forecast_loss = 0.07218, recon_loss = 0.05250, total_loss = 0.12468 ---- val_forecast_loss = 0.06237, val_recon_loss = 0.05065, val_total_loss = 0.11301 [69.9s]\r\n",
      "[Epoch 10] forecast_loss = 0.07098, recon_loss = 0.05192, total_loss = 0.12290 ---- val_forecast_loss = 0.05886, val_recon_loss = 0.04953, val_total_loss = 0.10839 [70.2s]\r\n",
      "-- Training done in 701s.\r\n",
      "Test forecast loss: 0.06164\r\n",
      "Test reconstruction loss: 0.04766\r\n",
      "Test total loss: 0.10930\r\n",
      "/kaggle/working/EnhancedMTADGAT/training.py:248: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  self.model.load_state_dict(torch.load(PATH, map_location=self.device))\r\n",
      "Predicting and calculating anomaly scores..\r\n",
      "100%|█████████████████████████████████████████| 528/528 [00:54<00:00,  9.66it/s]\r\n",
      "Predicting and calculating anomaly scores..\r\n",
      "100%|███████████████████████████████████████| 1670/1670 [02:53<00:00,  9.62it/s]\r\n",
      "Running POT with q=0.005, level=0.9..\r\n",
      "Initial threshold : 0.52238274\r\n",
      "Number of peaks : 13508\r\n",
      "Grimshaw maximum log-likelihood estimation ... [done]\r\n",
      "\tγ = -0.029150953516364098\r\n",
      "\tσ = 0.15917139411759643\r\n",
      "\tL = 11710.41806165298\r\n",
      "Extreme quantile (probability = 0.005): 0.9789868265748229\r\n",
      "100%|██████████████████████████████| 427517/427517 [00:00<00:00, 2263003.73it/s]\r\n",
      "0\r\n",
      "427517\r\n",
      "Finding best f1-score by searching for threshold..\r\n",
      "Results using epsilon method:\r\n",
      " {'f1': 0.809425034598025, 'precision': 0.9861319042402406, 'recall': 0.6864304518271116, 'TP': 37545, 'TN': 372293, 'FP': 528, 'FN': 17151, 'threshold': 0.7272295653820038, 'latency': 120.70887143841556, 'reg_level': 0}\r\n",
      "Results using peak-over-threshold method:\r\n",
      " {'f1': 0.7523721317715657, 'precision': 0.999212741173859, 'recall': 0.6033347958528348, 'TP': 33000, 'TN': 372795, 'FP': 26, 'FN': 21696, 'threshold': 0.978986826574823, 'latency': 229.21373996728576}\r\n",
      "Results using best f1 score search:\r\n",
      " {'f1': 0.8853572772043441, 'precision': 0.8621770992459714, 'recall': 0.9098288721460748, 'TP': 49764, 'TN': 364866, 'FP': 7955, 'FN': 4932, 'threshold': 0.3682000000000002, 'latency': 196.44230091426078}\r\n",
      "Saving output to output/SMAP/08052025_133438/<train/test>_output.pkl\r\n",
      "-- Done.\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataset SMAP --lookback 100 --epochs 10 --init_lr 1e-3 --use_transformer True --trans_enc_layers 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2de81c6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T13:52:55.962231Z",
     "iopub.status.busy": "2025-05-08T13:52:55.961941Z",
     "iopub.status.idle": "2025-05-08T13:53:03.601819Z",
     "shell.execute_reply": "2025-05-08T13:53:03.600760Z"
    },
    "papermill": {
     "duration": 8.054134,
     "end_time": "2025-05-08T13:53:03.603394",
     "exception": false,
     "start_time": "2025-05-08T13:52:55.549260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-08 13:52:59.547569: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1746712379.570573     127 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1746712379.578320     127 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "{'dynamic_graph': False, 'correlation_aware': False, 'use_transformer': False, 'dataset': 'MSL', 'group': '1-1', 'lookback': 100, 'normalize': True, 'spec_res': False, 'kernel_size': 7, 'use_gatv2': True, 'feat_gat_embed_dim': None, 'time_gat_embed_dim': None, 'trans_enc_layers': 2, 'gru_n_layers': 2, 'gru_hid_dim': 150, 'fc_n_layers': 3, 'fc_hid_dim': 150, 'recon_n_layers': 1, 'recon_hid_dim': 150, 'alpha': 0.2, 'epochs': 30, 'val_split': 0.1, 'bs': 256, 'init_lr': 0.0001, 'shuffle_dataset': True, 'dropout': 0.3, 'use_cuda': True, 'print_every': 1, 'log_tensorboard': True, 'scale_scores': False, 'use_mov_av': False, 'gamma': 1, 'level': None, 'q': None, 'dynamic_pot': False, 'comment': ''}\r\n",
      "load data of: MSL\r\n",
      "train:  0 None\r\n",
      "test:  0 None\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/EnhancedMTADGAT/train.py\", line 40, in <module>\r\n",
      "    (x_train, _), (x_test, y_test) = get_data(dataset, normalize=normalize)\r\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/kaggle/working/EnhancedMTADGAT/utils.py\", line 81, in get_data\r\n",
      "    f = open(os.path.join(prefix, dataset + \"_train.pkl\"), \"rb\")\r\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'datasets/data/processed/MSL_train.pkl'\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataset MSL --lookback 100 --epochs 30 --init_lr 1e-4 --use_transformer False --gru_n_layers 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff91cfc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T13:53:04.318213Z",
     "iopub.status.busy": "2025-05-08T13:53:04.317926Z",
     "iopub.status.idle": "2025-05-08T13:53:11.921506Z",
     "shell.execute_reply": "2025-05-08T13:53:11.920776Z"
    },
    "papermill": {
     "duration": 7.961439,
     "end_time": "2025-05-08T13:53:11.923011",
     "exception": false,
     "start_time": "2025-05-08T13:53:03.961572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-08 13:53:07.829814: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1746712387.852665     139 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1746712387.859480     139 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "{'dynamic_graph': False, 'correlation_aware': False, 'use_transformer': True, 'dataset': 'MSL', 'group': '1-1', 'lookback': 100, 'normalize': True, 'spec_res': False, 'kernel_size': 7, 'use_gatv2': True, 'feat_gat_embed_dim': None, 'time_gat_embed_dim': None, 'trans_enc_layers': 2, 'gru_n_layers': 1, 'gru_hid_dim': 150, 'fc_n_layers': 3, 'fc_hid_dim': 150, 'recon_n_layers': 1, 'recon_hid_dim': 150, 'alpha': 0.2, 'epochs': 30, 'val_split': 0.1, 'bs': 256, 'init_lr': 0.0001, 'shuffle_dataset': True, 'dropout': 0.3, 'use_cuda': True, 'print_every': 1, 'log_tensorboard': True, 'scale_scores': False, 'use_mov_av': False, 'gamma': 1, 'level': None, 'q': None, 'dynamic_pot': False, 'comment': ''}\r\n",
      "load data of: MSL\r\n",
      "train:  0 None\r\n",
      "test:  0 None\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/EnhancedMTADGAT/train.py\", line 40, in <module>\r\n",
      "    (x_train, _), (x_test, y_test) = get_data(dataset, normalize=normalize)\r\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/kaggle/working/EnhancedMTADGAT/utils.py\", line 81, in get_data\r\n",
      "    f = open(os.path.join(prefix, dataset + \"_train.pkl\"), \"rb\")\r\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'datasets/data/processed/MSL_train.pkl'\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataset MSL --lookback 100 --epochs 30 --init_lr 1e-4 --use_transformer True --trans_enc_layers 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35551543",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T13:53:12.680613Z",
     "iopub.status.busy": "2025-05-08T13:53:12.680333Z",
     "iopub.status.idle": "2025-05-08T13:53:20.260314Z",
     "shell.execute_reply": "2025-05-08T13:53:20.259585Z"
    },
    "papermill": {
     "duration": 7.932126,
     "end_time": "2025-05-08T13:53:20.261741",
     "exception": false,
     "start_time": "2025-05-08T13:53:12.329615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-08 13:53:16.201000: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1746712396.223054     151 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1746712396.229861     151 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "{'dynamic_graph': False, 'correlation_aware': False, 'use_transformer': False, 'dataset': 'MSL', 'group': '1-1', 'lookback': 100, 'normalize': True, 'spec_res': False, 'kernel_size': 7, 'use_gatv2': True, 'feat_gat_embed_dim': None, 'time_gat_embed_dim': None, 'trans_enc_layers': 2, 'gru_n_layers': 2, 'gru_hid_dim': 150, 'fc_n_layers': 3, 'fc_hid_dim': 150, 'recon_n_layers': 1, 'recon_hid_dim': 150, 'alpha': 0.2, 'epochs': 30, 'val_split': 0.1, 'bs': 256, 'init_lr': 0.001, 'shuffle_dataset': True, 'dropout': 0.3, 'use_cuda': True, 'print_every': 1, 'log_tensorboard': True, 'scale_scores': False, 'use_mov_av': False, 'gamma': 1, 'level': None, 'q': None, 'dynamic_pot': False, 'comment': ''}\r\n",
      "load data of: MSL\r\n",
      "train:  0 None\r\n",
      "test:  0 None\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/EnhancedMTADGAT/train.py\", line 40, in <module>\r\n",
      "    (x_train, _), (x_test, y_test) = get_data(dataset, normalize=normalize)\r\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/kaggle/working/EnhancedMTADGAT/utils.py\", line 81, in get_data\r\n",
      "    f = open(os.path.join(prefix, dataset + \"_train.pkl\"), \"rb\")\r\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'datasets/data/processed/MSL_train.pkl'\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataset MSL --lookback 100 --epochs 30 --init_lr 1e-3 --use_transformer False --gru_n_layers 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb3ad201",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T13:53:21.038636Z",
     "iopub.status.busy": "2025-05-08T13:53:21.037931Z",
     "iopub.status.idle": "2025-05-08T13:53:28.734019Z",
     "shell.execute_reply": "2025-05-08T13:53:28.733251Z"
    },
    "papermill": {
     "duration": 8.120171,
     "end_time": "2025-05-08T13:53:28.736207",
     "exception": false,
     "start_time": "2025-05-08T13:53:20.616036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-08 13:53:24.651669: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1746712404.674243     163 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1746712404.680974     163 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "{'dynamic_graph': False, 'correlation_aware': False, 'use_transformer': True, 'dataset': 'MSL', 'group': '1-1', 'lookback': 100, 'normalize': True, 'spec_res': False, 'kernel_size': 7, 'use_gatv2': True, 'feat_gat_embed_dim': None, 'time_gat_embed_dim': None, 'trans_enc_layers': 2, 'gru_n_layers': 1, 'gru_hid_dim': 150, 'fc_n_layers': 3, 'fc_hid_dim': 150, 'recon_n_layers': 1, 'recon_hid_dim': 150, 'alpha': 0.2, 'epochs': 30, 'val_split': 0.1, 'bs': 256, 'init_lr': 0.001, 'shuffle_dataset': True, 'dropout': 0.3, 'use_cuda': True, 'print_every': 1, 'log_tensorboard': True, 'scale_scores': False, 'use_mov_av': False, 'gamma': 1, 'level': None, 'q': None, 'dynamic_pot': False, 'comment': ''}\r\n",
      "load data of: MSL\r\n",
      "train:  0 None\r\n",
      "test:  0 None\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/EnhancedMTADGAT/train.py\", line 40, in <module>\r\n",
      "    (x_train, _), (x_test, y_test) = get_data(dataset, normalize=normalize)\r\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/kaggle/working/EnhancedMTADGAT/utils.py\", line 81, in get_data\r\n",
      "    f = open(os.path.join(prefix, dataset + \"_train.pkl\"), \"rb\")\r\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'datasets/data/processed/MSL_train.pkl'\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataset MSL --lookback 100 --epochs 30 --init_lr 1e-3 --use_transformer True --trans_enc_layers 2"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4544.322622,
   "end_time": "2025-05-08T13:53:29.411793",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-08T12:37:45.089171",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
